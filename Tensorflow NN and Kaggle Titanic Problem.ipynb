{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 739,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import sklearn as sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 740,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_data_df = pd.read_csv(\"train.csv\", header =0)\n",
    "test_data_df = pd.read_csv(\"test.csv\", header = 0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 741,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def transform_input_data(df):\n",
    "    #transform gender column into categorical values\n",
    "    sex_categorical_cols = pd.get_dummies(df['Sex'], prefix='sex', drop_first=False)\n",
    "    df = pd.concat([df, sex_categorical_cols], axis = 1)\n",
    "\n",
    "    #transform fare column into fare class\n",
    "    df['FareBucket'] = df['Fare']-(df['Fare']%10)\n",
    "    \n",
    "    #transform age into age bucket\n",
    "    df['AgeBucket'] = df['Age']-(df['Age']%10)\n",
    "    \n",
    "    #treat missing Embarked\n",
    "    df['EmbarkedVal'] = df.Embarked.map({'C':0, 'Q':1, 'S':2})\n",
    "    embarkedMedian = df.EmbarkedVal.dropna().median()\n",
    "    df.loc[(df.EmbarkedVal.isnull()), 'EmbarkedVal'] = embarkedMedian\n",
    "    \n",
    "    #transform embarked into categorical\n",
    "    embarked_categorical_cols = pd.get_dummies(df['EmbarkedVal'], prefix='embarkedval', drop_first=False)\n",
    "    df = pd.concat([df, embarked_categorical_cols], axis=1)\n",
    "    \n",
    "    #treat missing ages\n",
    "    girls_age_median = df[(df.Name.str.contains('Miss'))]['Age'].dropna().median()\n",
    "    boys_age_median = df[(df.Name.str.contains('Master'))]['Age'].dropna().median()\n",
    "    male_age_median = df[(df['Sex'] == 'male')]['Age'].dropna().median()\n",
    "    female_age_median = df[(df['Sex'] == 'female')]['Age'].dropna().median()\n",
    "    \n",
    "    df.loc[((df.Age.isnull()) & (df.Sex == 'male')), 'AgeBucket'] = male_age_median - (male_age_median%10)\n",
    "    df.loc[((df.Age.isnull()) & (df.Sex == 'female')), 'AgeBucket'] = female_age_median - (female_age_median%10)\n",
    "    \n",
    "    df.loc[((df.Age.isnull()) & (df.Name.str.contains('Miss'))), 'AgeBucket'] = girls_age_median - (girls_age_median%10)\n",
    "    df.loc[((df.Age.isnull()) & (df.Name.str.contains('Master'))), 'AgeBucket'] = boys_age_median - (boys_age_median%10)\n",
    "    \n",
    "    #treat missing fare buckets\n",
    "    for pclass in range(3):\n",
    "        classFareMean = df[(df.Pclass == pclass+1)]['Fare'].dropna().mean()\n",
    "        df.loc[((df.Fare.isnull()) & (df.Pclass == pclass+1)), 'FareBucket'] =  classFareMean- (classFareMean%10)\n",
    "    \n",
    "    #transform embarked into categorical\n",
    "    sibsp_categorical_cols = pd.get_dummies(df['SibSp'], prefix='sibsp', drop_first=False)\n",
    "    df = pd.concat([df, sibsp_categorical_cols], axis=1)\n",
    "    \n",
    "    #transform embarked into categorical\n",
    "    pclass_categorical_cols = pd.get_dummies(df['Pclass'], prefix='pclass', drop_first=False)\n",
    "    df = pd.concat([df, pclass_categorical_cols], axis=1)\n",
    "    \n",
    "    #transform embarked into categorical\n",
    "    #parch_categorical_cols = pd.get_dummies(df['Parch'], prefix='parch', drop_first=False)\n",
    "    #df = pd.concat([df, parch_categorical_cols], axis=1)\n",
    "    \n",
    "    #transform cabin info\n",
    "    df['CabinInfo'] = train_data_df.Cabin.astype(str).str[0] #just fetching the cabin A/B/C/D etc and leaving nan as they are and they ll be treated as another class\n",
    "    cabininfo_categorical_cols = pd.get_dummies(df['CabinInfo'], prefix='cabininfo', drop_first=False)\n",
    "    df = pd.concat([df, cabininfo_categorical_cols], axis=1)\n",
    "    \n",
    "    #drop other cols\n",
    "    cols_to_drop = ['Name', 'Sex', 'Age', 'SibSp', 'Ticket', 'Fare', 'Pclass', 'Cabin', 'CabinInfo', 'Embarked', 'EmbarkedVal', 'PassengerId']\n",
    "    df = df.drop(cols_to_drop, axis=1)\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 742,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def transform_output_data(df):\n",
    "    #transform gender column into categorical values\n",
    "    survived_categorical_cols = pd.get_dummies(df['Survived'], prefix='survived', drop_first=False)\n",
    "    df = pd.concat([df, survived_categorical_cols], axis = 1)\n",
    "    df = df.drop(['Survived'], axis=1)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 743,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# y train\n",
    "train_data_y = transform_output_data(pd.DataFrame(train_data_df['Survived']))\n",
    "\n",
    "# x train\n",
    "train_data_x = transform_input_data(train_data_df)\n",
    "train_data_x = train_data_x.drop(['Survived'], axis=1)\n",
    "\n",
    "# x test\n",
    "test_data_x = transform_input_data(test_data_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 744,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#train_data_x\n",
    "#train_data_y\n",
    "#train_data_x['FareBucket'].unique()\n",
    "#train_data_df['Cabin'].unique()\n",
    "#train_data_df[(train_data_df['Cabin'].isnull())]\n",
    "#rain_data_df['Parch'].unique()\n",
    "#train_data_df['CabinInfo'] = train_data_df.Cabin[0]\n",
    "#train_data_df['CabinInfo'] = train_data_df.Cabin.astype(str).str[0]\n",
    "#train_data_df['CabinInfo'].unique()\n",
    "#test_data_x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 796,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#start preparing for tensorflow model\n",
    "X_train_total = train_data_x.values\n",
    "Y_train_total = train_data_y.values\n",
    "\n",
    "records = len(X_train_total)\n",
    "train_test_split_per = 0.9\n",
    "\n",
    "# training data sets\n",
    "X_train = X_train_total[:int(records*train_test_split_per)]\n",
    "Y_train = Y_train_total[:int(records*train_test_split_per)]\n",
    "\n",
    "# local test data sets\n",
    "X_test_0 = X_train_total[int(records*train_test_split_per):]\n",
    "Y_test_0 = Y_train_total[int(records*train_test_split_per):]\n",
    "\n",
    "# kaggle test data set that should be predicted\n",
    "X_test_final = test_data_x.values\n",
    "\n",
    "#hyper parameters\n",
    "learning_rate = 0.01\n",
    "epochs = 150\n",
    "batch_size = 128\n",
    "display_step = 1\n",
    "\n",
    "#hyper parameter selection options\n",
    "#learning_rates = [0.1, 0.09, 0.01, 0.009, 0.001, 0.0001]\n",
    "#epoch_list = [10, 50, 100, 150]\n",
    "#batch_sizes = [128, 256, 512]\n",
    "\n",
    "\n",
    "#shapes of inputs and weights\n",
    "n_input_features = X_train.shape[1]\n",
    "n_classes = Y_train.shape[1]\n",
    "\n",
    "#n_hidden_layer = int(round((n_input_features + n_classes) / 2)) #an approximation to start with\n",
    "n_hidden_layer = 15"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 797,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "15"
      ]
     },
     "execution_count": 797,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_hidden_layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 798,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#form weights and biases variables\n",
    "weights = {\n",
    "    'hidden_layer': tf.Variable(tf.random_normal([n_input_features, n_hidden_layer])),\n",
    "    'output_layer': tf.Variable(tf.random_normal([n_hidden_layer, n_classes]))\n",
    "}\n",
    "biases = {\n",
    "    'hidden_layer': tf.Variable(tf.random_normal([n_hidden_layer])),\n",
    "    'output_layer': tf.Variable(tf.random_normal([n_classes]))\n",
    "}\n",
    "\n",
    "#tf model\n",
    "x = tf.placeholder(tf.float32, [None, n_input_features])\n",
    "y = tf.placeholder(tf.float32, [None, n_classes])\n",
    "\n",
    "#lr = tf.placeholder(tf.float32)\n",
    "\n",
    "#hidden layer with ReLU\n",
    "hidden_layer = tf.add(tf.matmul(x, weights['hidden_layer']), biases['hidden_layer'])\n",
    "hidden_layer = tf.nn.relu(hidden_layer)\n",
    "#output layer\n",
    "logits = tf.add(tf.matmul(hidden_layer, weights['output_layer']), biases['output_layer'])\n",
    "\n",
    "predictions = tf.argmax(tf.nn.softmax(logits=logits),1)\n",
    "#cost\n",
    "cost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits=logits, labels=y))\n",
    "#optimizer \n",
    "optimizer = tf.train.GradientDescentOptimizer(learning_rate=learning_rate).minimize(cost)\n",
    "\n",
    "#init\n",
    "init = tf.global_variables_initializer()\n",
    "\n",
    "#accuracy and predictions\n",
    "correct_predictions = tf.equal(tf.argmax(logits, 1), tf.argmax(y, 1))\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_predictions, tf.float32))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 799,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import math\n",
    "def get_batches(batch_size, features, labels):\n",
    "    batch_count = math.ceil(len(features)/batch_size)\n",
    "    batches = []\n",
    "    for i in range(batch_count):\n",
    "        feature_set, labels_set = [],[]\n",
    "        if i == batch_count - 1:\n",
    "            feature_set = features[i*batch_size:][:]\n",
    "            labels_set = labels[i*batch_size:][:]\n",
    "        else:\n",
    "            feature_set = features[i*batch_size:(i+1)*batch_size][:]\n",
    "            labels_set = labels[i*batch_size:(i+1)*batch_size][:]\n",
    "        current_batch = [feature_set, labels_set]\n",
    "        batches.append(current_batch)\n",
    "    return batches "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 800,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0001 cost= 11.795425415 val acc: nan\n",
      "Epoch: 0002 cost= 18.160991669 val acc: nan\n",
      "Epoch: 0003 cost= 7.282359600 val acc: nan\n",
      "Epoch: 0004 cost= 6.239048004 val acc: nan\n",
      "Epoch: 0005 cost= 4.836873531 val acc: nan\n",
      "Epoch: 0006 cost= 1.495831251 val acc: nan\n",
      "Epoch: 0007 cost= 3.208735228 val acc: nan\n",
      "Epoch: 0008 cost= 5.939539433 val acc: nan\n",
      "Epoch: 0009 cost= 4.376293182 val acc: nan\n",
      "Epoch: 0010 cost= 1.727697611 val acc: nan\n",
      "Epoch: 0011 cost= 2.343883753 val acc: nan\n",
      "Epoch: 0012 cost= 1.088119864 val acc: nan\n",
      "Epoch: 0013 cost= 1.458680391 val acc: nan\n",
      "Epoch: 0014 cost= 2.924477816 val acc: nan\n",
      "Epoch: 0015 cost= 1.019582152 val acc: nan\n",
      "Epoch: 0016 cost= 1.745906830 val acc: nan\n",
      "Epoch: 0017 cost= 0.733402967 val acc: nan\n",
      "Epoch: 0018 cost= 0.927239776 val acc: nan\n",
      "Epoch: 0019 cost= 1.061872244 val acc: nan\n",
      "Epoch: 0020 cost= 0.875206947 val acc: nan\n",
      "Epoch: 0021 cost= 0.703107655 val acc: nan\n",
      "Epoch: 0022 cost= 0.872576952 val acc: nan\n",
      "Epoch: 0023 cost= 0.999517024 val acc: nan\n",
      "Epoch: 0024 cost= 0.650040030 val acc: nan\n",
      "Epoch: 0025 cost= 0.604562283 val acc: nan\n",
      "Epoch: 0026 cost= 0.634412944 val acc: nan\n",
      "Epoch: 0027 cost= 0.583712280 val acc: nan\n",
      "Epoch: 0028 cost= 0.766527712 val acc: nan\n",
      "Epoch: 0029 cost= 0.780482650 val acc: nan\n",
      "Epoch: 0030 cost= 0.654495835 val acc: nan\n",
      "Epoch: 0031 cost= 0.586098969 val acc: nan\n",
      "Epoch: 0032 cost= 0.603994668 val acc: nan\n",
      "Epoch: 0033 cost= 0.587737560 val acc: nan\n",
      "Epoch: 0034 cost= 0.608772397 val acc: nan\n",
      "Epoch: 0035 cost= 0.590696931 val acc: nan\n",
      "Epoch: 0036 cost= 0.591318965 val acc: nan\n",
      "Epoch: 0037 cost= 0.588475585 val acc: nan\n",
      "Epoch: 0038 cost= 0.597805262 val acc: nan\n",
      "Epoch: 0039 cost= 0.579857111 val acc: nan\n",
      "Epoch: 0040 cost= 0.580309927 val acc: nan\n",
      "Epoch: 0041 cost= 0.576116502 val acc: nan\n",
      "Epoch: 0042 cost= 0.572758079 val acc: nan\n",
      "Epoch: 0043 cost= 0.569210649 val acc: nan\n",
      "Epoch: 0044 cost= 0.567522526 val acc: nan\n",
      "Epoch: 0045 cost= 0.566641748 val acc: nan\n",
      "Epoch: 0046 cost= 0.564618111 val acc: nan\n",
      "Epoch: 0047 cost= 0.562753141 val acc: nan\n",
      "Epoch: 0048 cost= 0.561007202 val acc: nan\n",
      "Epoch: 0049 cost= 0.559010506 val acc: nan\n",
      "Epoch: 0050 cost= 0.557474792 val acc: nan\n",
      "Epoch: 0051 cost= 0.555882096 val acc: nan\n",
      "Epoch: 0052 cost= 0.554358840 val acc: nan\n",
      "Epoch: 0053 cost= 0.552981496 val acc: nan\n",
      "Epoch: 0054 cost= 0.551490724 val acc: nan\n",
      "Epoch: 0055 cost= 0.550208986 val acc: nan\n",
      "Epoch: 0056 cost= 0.548997641 val acc: nan\n",
      "Epoch: 0057 cost= 0.547914028 val acc: nan\n",
      "Epoch: 0058 cost= 0.546860874 val acc: nan\n",
      "Epoch: 0059 cost= 0.545779228 val acc: nan\n",
      "Epoch: 0060 cost= 0.544768274 val acc: nan\n",
      "Epoch: 0061 cost= 0.543585658 val acc: nan\n",
      "Epoch: 0062 cost= 0.542539775 val acc: nan\n",
      "Epoch: 0063 cost= 0.541445076 val acc: nan\n",
      "Epoch: 0064 cost= 0.540290236 val acc: nan\n",
      "Epoch: 0065 cost= 0.538428307 val acc: nan\n",
      "Epoch: 0066 cost= 0.536659658 val acc: nan\n",
      "Epoch: 0067 cost= 0.537434757 val acc: nan\n",
      "Epoch: 0068 cost= 0.536179900 val acc: nan\n",
      "Epoch: 0069 cost= 0.536457121 val acc: nan\n",
      "Epoch: 0070 cost= 0.535434604 val acc: nan\n",
      "Epoch: 0071 cost= 0.535116553 val acc: nan\n",
      "Epoch: 0072 cost= 0.534545541 val acc: nan\n",
      "Epoch: 0073 cost= 0.534005702 val acc: nan\n",
      "Epoch: 0074 cost= 0.533468127 val acc: nan\n",
      "Epoch: 0075 cost= 0.534546137 val acc: nan\n",
      "Epoch: 0076 cost= 0.534206510 val acc: nan\n",
      "Epoch: 0077 cost= 0.533897281 val acc: nan\n",
      "Epoch: 0078 cost= 0.533586800 val acc: nan\n",
      "Epoch: 0079 cost= 0.533277273 val acc: nan\n",
      "Epoch: 0080 cost= 0.531767428 val acc: nan\n",
      "Epoch: 0081 cost= 0.532786608 val acc: nan\n",
      "Epoch: 0082 cost= 0.531222820 val acc: nan\n",
      "Epoch: 0083 cost= 0.532216430 val acc: nan\n",
      "Epoch: 0084 cost= 0.530672848 val acc: nan\n",
      "Epoch: 0085 cost= 0.531701684 val acc: nan\n",
      "Epoch: 0086 cost= 0.530102372 val acc: nan\n",
      "Epoch: 0087 cost= 0.531035304 val acc: nan\n",
      "Epoch: 0088 cost= 0.529365122 val acc: nan\n",
      "Epoch: 0089 cost= 0.530218840 val acc: nan\n",
      "Epoch: 0090 cost= 0.530001342 val acc: nan\n",
      "Epoch: 0091 cost= 0.528212309 val acc: nan\n",
      "Epoch: 0092 cost= 0.529022753 val acc: nan\n",
      "Epoch: 0093 cost= 0.528806090 val acc: nan\n",
      "Epoch: 0094 cost= 0.528546333 val acc: nan\n",
      "Epoch: 0095 cost= 0.528239131 val acc: nan\n",
      "Epoch: 0096 cost= 0.528082132 val acc: nan\n",
      "Epoch: 0097 cost= 0.527861297 val acc: nan\n",
      "Epoch: 0098 cost= 0.527699649 val acc: nan\n",
      "Epoch: 0099 cost= 0.527501047 val acc: nan\n",
      "Epoch: 0100 cost= 0.527211189 val acc: nan\n",
      "Epoch: 0101 cost= 0.526917636 val acc: nan\n",
      "Epoch: 0102 cost= 0.526628315 val acc: nan\n",
      "Epoch: 0103 cost= 0.526284218 val acc: nan\n",
      "Epoch: 0104 cost= 0.525896132 val acc: nan\n",
      "Epoch: 0105 cost= 0.525508523 val acc: nan\n",
      "Epoch: 0106 cost= 0.525102675 val acc: nan\n",
      "Epoch: 0107 cost= 0.524694026 val acc: nan\n",
      "Epoch: 0108 cost= 0.524300873 val acc: nan\n",
      "Epoch: 0109 cost= 0.523897111 val acc: nan\n",
      "Epoch: 0110 cost= 0.523514390 val acc: nan\n",
      "Epoch: 0111 cost= 0.523155689 val acc: nan\n",
      "Epoch: 0112 cost= 0.522817016 val acc: nan\n",
      "Epoch: 0113 cost= 0.522479415 val acc: nan\n",
      "Epoch: 0114 cost= 0.522256255 val acc: nan\n",
      "Epoch: 0115 cost= 0.521851718 val acc: nan\n",
      "Epoch: 0116 cost= 0.521573842 val acc: nan\n",
      "Epoch: 0117 cost= 0.521280050 val acc: nan\n",
      "Epoch: 0118 cost= 0.520993888 val acc: nan\n",
      "Epoch: 0119 cost= 0.520693660 val acc: nan\n",
      "Epoch: 0120 cost= 0.520428896 val acc: nan\n",
      "Epoch: 0121 cost= 0.520259023 val acc: nan\n",
      "Epoch: 0122 cost= 0.520054221 val acc: nan\n",
      "Epoch: 0123 cost= 0.519941390 val acc: nan\n",
      "Epoch: 0124 cost= 0.519857526 val acc: nan\n",
      "Epoch: 0125 cost= 0.519565642 val acc: nan\n",
      "Epoch: 0126 cost= 0.519246459 val acc: nan\n",
      "Epoch: 0127 cost= 0.518951595 val acc: nan\n",
      "Epoch: 0128 cost= 0.518589437 val acc: nan\n",
      "Epoch: 0129 cost= 0.518257022 val acc: nan\n",
      "Epoch: 0130 cost= 0.517938197 val acc: nan\n",
      "Epoch: 0131 cost= 0.517605484 val acc: nan\n",
      "Epoch: 0132 cost= 0.517275453 val acc: nan\n",
      "Epoch: 0133 cost= 0.516998529 val acc: nan\n",
      "Epoch: 0134 cost= 0.516751826 val acc: nan\n",
      "Epoch: 0135 cost= 0.516475856 val acc: nan\n",
      "Epoch: 0136 cost= 0.516224563 val acc: nan\n",
      "Epoch: 0137 cost= 0.516040266 val acc: nan\n",
      "Epoch: 0138 cost= 0.515807450 val acc: nan\n",
      "Epoch: 0139 cost= 0.515614688 val acc: nan\n",
      "Epoch: 0140 cost= 0.515412033 val acc: nan\n",
      "Epoch: 0141 cost= 0.515204132 val acc: nan\n",
      "Epoch: 0142 cost= 0.514990985 val acc: nan\n",
      "Epoch: 0143 cost= 0.514750481 val acc: nan\n",
      "Epoch: 0144 cost= 0.514507353 val acc: nan\n",
      "Epoch: 0145 cost= 0.514264524 val acc: nan\n",
      "Epoch: 0146 cost= 0.514021754 val acc: nan\n",
      "Epoch: 0147 cost= 0.513765335 val acc: nan\n",
      "Epoch: 0148 cost= 0.513504744 val acc: nan\n",
      "Epoch: 0149 cost= 0.513286829 val acc: nan\n",
      "Epoch: 0150 cost= 0.513061345 val acc: nan\n",
      "Optimization Finished!\n",
      "Test Accuracy: 0.7111111283302307\n",
      "[0 0 0 0 1 0 0 1 1 1 0 0 1 0 1 1 0 0 1 0 1 1 1 1 1 0 1 0 0 1 0 1 0 1 1 0 0\n",
      " 0 0 1 0 1 0 1 1 0 0 0 1 1 1 0 1 1 0 1 0 0 0 1 0 0 0 1 1 1 0 1 0 1 1 0 0 0\n",
      " 1 1 0 0 0 1 1 1 0 0 1 0 1 1 0 1 1 0 1 0 0 0 0 0 0 0 1 1 0 0 0 1 0 0 0 1 0\n",
      " 1 1 1 1 1 0 1 1 1 1 0 1 0 0 1 0 1 0 0 0 0 1 0 0 0 0 1 0 1 1 1 1 1 0 0 0 0\n",
      " 1 0 1 0 0 1 1 0 1 0 0 1 1 1 1 0 0 1 1 1 1 0 0 0 0 0 0 1 1 0 1 1 0 1 1 0 1\n",
      " 0 1 0 1 0 0 1 1 0 1 0 1 1 1 0 1 1 1 1 1 0 0 1 0 0 0 0 1 0 0 1 1 1 1 0 1 0\n",
      " 1 0 0 1 0 1 0 0 1 1 0 0 1 0 1 0 1 1 0 0 1 0 1 1 1 0 0 0 1 0 1 0 0 0 0 0 1\n",
      " 0 0 0 1 0 0 0 0 0 0 0 1 0 1 0 0 0 1 0 0 1 0 1 1 1 1 0 0 1 0 0 1 0 0 1 0 0\n",
      " 1 1 1 0 0 0 0 0 1 0 1 1 1 0 0 0 0 0 1 1 1 1 0 1 0 0 1 0 1 0 1 1 1 0 0 0 0\n",
      " 1 0 0 0 0 1 1 1 0 1 1 1 0 1 0 1 0 1 1 1 1 1 0 1 0 0 0 1 1 0 0 1 1 0 1 1 0\n",
      " 1 1 0 0 1 1 0 1 1 1 0 0 1 1 1 1 0 0 0 0 1 0 1 0 0 1 0 1 0 0 1 0 1 0 0 0 1\n",
      " 1 1 1 1 1 0 0 1 0 0 0]\n"
     ]
    }
   ],
   "source": [
    "#start tf session\n",
    "train_batches = get_batches(batch_size, X_train, Y_train)\n",
    "   \n",
    "with tf.Session() as session:\n",
    "    session.run(init)\n",
    "    \n",
    "    #each training cycle\n",
    "    for epoch_i in range(epochs):\n",
    "        \n",
    "        #for all batches\n",
    "        for batch_features, batch_labels in train_batches:\n",
    "            \n",
    "            indices = np.arange(len(batch_features))\n",
    "            np.random.shuffle(indices)\n",
    "            \n",
    "            cv_split_index = int(0.9*(len(batch_features))) #split into cross validation set and training set for this epoch & batch\n",
    "            \n",
    "            train_batch_features = batch_features[indices[:cv_split_index]]\n",
    "            train_batch_labels = batch_labels[indices[:cv_split_index]]\n",
    "            \n",
    "            val_batch_features = batch_features[indices[cv_split_index:]]\n",
    "            val_batch_labels = batch_labels[indices[cv_split_index:]]\n",
    "            \n",
    "            train_feed_dict = {x: train_batch_features, y: train_batch_labels}\n",
    "            #run the optimizer\n",
    "            session.run(optimizer, feed_dict=train_feed_dict)\n",
    "            \n",
    "        # Display logs per epoch step\n",
    "        if epoch_i % display_step == 0:\n",
    "            current_cost = session.run(cost, feed_dict={x: train_batch_features, y: train_batch_labels})\n",
    "            validation_accuracy = session.run(accuracy,  feed_dict={x: val_batch_features, y: val_batch_labels})\n",
    "            print(\"Epoch:\", '%04d' % (epoch_i+1), \"cost=\", \"{:.9f}\".format(current_cost), \"val acc:\", \"{:.9f}\".format(validation_accuracy))\n",
    "            \n",
    "    print(\"Optimization Finished!\")\n",
    "    \n",
    "    #testing the model\n",
    "    \n",
    "    test_accuracy = session.run(accuracy,  feed_dict={x: X_test_0, y: Y_test_0, lr: learn_rate})\n",
    "    print(\"Test Accuracy: {}\".format(test_accuracy))\n",
    "    \n",
    "    #predict for test data - kaggle output data\n",
    "    output = session.run(predictions, feed_dict={x: X_test_final, lr: learn_rate})\n",
    "    print(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 793,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 1, 1, 0, 0, 0, 0, 1, 0, 1,\n",
       "       1, 1, 0, 1, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 1, 0, 0, 1, 1, 0,\n",
       "       0, 0, 1, 1, 1, 1, 0, 1, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 1, 0, 0, 1,\n",
       "       1, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 1, 1, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0,\n",
       "       0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1,\n",
       "       1, 0, 1, 1, 1, 1, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0,\n",
       "       0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 1, 0, 0, 1, 0,\n",
       "       1, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 1, 0, 1, 1, 0,\n",
       "       1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 1, 1, 0, 0, 1, 0, 1, 1, 0, 0, 0,\n",
       "       0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 1, 1, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0,\n",
       "       1, 0, 0, 0, 1, 0, 1, 0, 0, 1, 1, 0, 1, 0, 0, 0, 1, 0, 1, 1, 0, 0, 1,\n",
       "       0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 1,\n",
       "       0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0,\n",
       "       0, 0, 1, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0,\n",
       "       0, 0, 1, 0, 1, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0,\n",
       "       1, 0, 1, 0, 0, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 1, 1,\n",
       "       1, 1, 0, 1, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 1, 1,\n",
       "       0, 0, 0, 0, 1, 0, 1, 0, 0, 1, 0, 1, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 0,\n",
       "       1, 0, 0, 1], dtype=int64)"
      ]
     },
     "execution_count": 793,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 794,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "result = pd.concat((test_data_df['PassengerId'], pd.DataFrame(output)), axis=1)\n",
    "result.to_csv('result_pd.csv', index_label=False, index =False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 795,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
